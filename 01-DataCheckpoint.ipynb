{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "*(Replace with your team names and contributions using the [CRediT taxonomy](https://credit.niso.org).)*\n",
    "\n",
    "- *Member 1*: Conceptualization, Background research, Data curation, Writing (original draft)\n",
    "- *Member 2*: Data curation, Analysis, Software, Visualization\n",
    "- *Member 3*: Methodology, Analysis, Visualization, Writing (review and editing)\n",
    "- *Member 4*: Project administration, Writing (original draft), Writing (review and editing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How have housing prices and affordability changed over time in regions surrounding University of California (UC) campuses, and how do these trends relate to local income levels and broader economic conditions?\n",
    "\n",
    "Specifically, we examine whether housing prices near UC campuses have increased faster than median household income and how these trends differ across regions (e.g., Irvine, La Jolla, Berkeley, Los Angeles) and time periods. The main metrics are median home price (or home value index), median household income, and affordability (e.g., price-to-income ratio or rent burden). The analysis is primarily descriptive and comparative. We will visualize price and income trends, compare regions, and assess changes in affordability over at least 10 to 20 years using public data from government and real-estate sources (e.g., Zillow, U.S. Census/ACS, FRED).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housing affordability has become a major economic and social issue in California, particularly in regions with high demand and limited housing supply. Areas surrounding University of California campuses often experience additional housing pressure due to student populations, faculty demand, and local economic growth. Prior research has shown that housing prices in California have increased significantly over the past two decades, frequently outpacing wage growth and contributing to affordability challenges for renters and homeowners alike.\n",
    "\n",
    "Several public data sources provide context. Zillow's housing market reports document long-term growth in home values across major U.S. metropolitan areas, with especially rapid increases in coastal California cities. U.S. Census data and American Community Survey (ACS) reports provide evidence that median household income growth has been slower and uneven across regions. Our project focuses on UC-adjacent regions (e.g., Irvine, La Jolla, Berkeley, Los Angeles) and compares affordability trends across multiple campuses using Zillow, Census/ACS, and FRED data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that housing prices in regions surrounding UC campuses have increased faster than median household income over time, leading to decreased affordability. We also expect that UC regions in major metropolitan or coastal areas (e.g., near UC Berkeley or UCLA) will exhibit higher prices and lower affordability compared to UC campuses in less dense regions (e.g., UC Riverside or UC Merced). This is based on prior evidence that coastal and urban California markets have seen stronger price growth and that university towns often face extra demand from students and staff, while income growth has been slower and uneven across the state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "**Dataset 1: Zillow Home Value Index (ZHVI), Single-Family Residences**\n",
    "- **Dataset name:** Zip_Zhvi_SingleFamilyResidence (ZIP code level, single-family home values).\n",
    "- **Link:** [Zillow Research Data](https://www.zillow.com/research/data/). For this checkpoint we use a public mirror: `https://raw.githubusercontent.com/noahgift/real_estate_ml/master/data/Zip_Zhvi_SingleFamilyResidence_2018.csv`.\n",
    "- **Observations:** One row per ZIP code. Thousands of ZIPs nationally; we filter to California and further to UC-adjacent areas.\n",
    "- **Variables:** RegionID, RegionName (ZIP), State, Metro, CountyName, and many date columns (e.g., 1996-04 to 2018-08) with typical home value in dollars for that month. We use RegionName/State/CountyName for geography and the date columns for price levels and trends over time.\n",
    "- **Relevance:** Provides housing price levels and growth over time at fine geography (ZIP). We can aggregate to county or metro and align with UC campus regions (e.g., Irvine, La Jolla, Berkeley, Los Angeles).\n",
    "- **Shortcomings:** Data end in 2018 in this mirror. Official Zillow data are updated monthly. Geography is ZIP, so we must map ZIPs to counties/metros for UC regions. Single-family only (excludes condos).\n",
    "\n",
    "**Dataset 2: American Community Survey (ACS) – Median Household Income**\n",
    "\n",
    "- **Dataset name:** ACS 5-Year Estimates, Table B19013\n",
    "- **Link:** https://data.census.gov/table/ACSDT5Y2023.B19013?q=ACS+5-year+B19013+county+California&g=040XX00US06$0500000\n",
    "- **Source:** U.S. Census Bureau  \n",
    "- **Observations:** One row per county per year  \n",
    "\n",
    "- **Variables:** County name, year, median household income (USD)  \n",
    "\n",
    "- **Relevance:** Provides multi-year county-level income data, enabling comparison of income growth with housing price growth over time.  \n",
    "\n",
    "- **Shortcomings:** ACS is survey-based and represents estimates rather than exact administrative records.\n",
    "\n",
    "**Combining the datasets:** We will join on geography. Zillow data have CountyName; income data have county. We will filter Zillow to California, aggregate or select ZIPs for UC-adjacent counties (e.g., Orange, San Diego, Alameda, Los Angeles), and merge with county-level income. For time series we use Zillow date columns and, when available, multi-year income data (e.g., from Census ACS) for the same counties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading Zip_Zhvi_SingleFamilyResidence_2018.csv:   0%|          | 0.00/8.78M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading Zip_Zhvi_SingleFamilyResidence_2018.csv:  72%|███████▏  | 6.34M/8.78M [00:00<00:00, 63.4MB/s]\u001b[A\n",
      "Downloading Zip_Zhvi_SingleFamilyResidence_2018.csv: 16.8MB [00:00, 87.7MB/s]                            \u001b[A\n",
      "Downloading Zip_Zhvi_SingleFamilyResidence_2018.csv: 27.5MB [00:00, 96.3MB/s]\u001b[A\n",
      "Overall Download Progress:  50%|█████     | 1/2 [00:05<00:05,  5.94s/it]     \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: Zip_Zhvi_SingleFamilyResidence_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 2022-income-limits.csv:   0%|          | 0.00/15.4k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 2/2 [00:06<00:00,  3.39s/it]       \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 2022-income-limits.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./modules')\n",
    "\n",
    "import get_data\n",
    "\n",
    "datafiles = [\n",
    "    {'url': 'https://raw.githubusercontent.com/noahgift/real_estate_ml/master/data/Zip_Zhvi_SingleFamilyResidence_2018.csv', 'filename': 'Zip_Zhvi_SingleFamilyResidence_2018.csv'},\n",
    "    {'url': 'https://data.ca.gov/dataset/d56fc70f-5566-4030-8854-1ce72c93e100/resource/49eb1f40-d50a-4dde-98ca-0450d69c4617/download/2022-income-limits.csv', 'filename': '2022-income-limits.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles, destination_directory='data/00-raw/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zillow Home Value Index (ZHVI), Single-Family by ZIP\n",
    "\n",
    "**Metrics and units.** The dataset gives the Zillow Home Value Index (ZHVI) for single-family residences at the ZIP code level. Each date column (e.g., 1996-04, 2018-08) contains the estimated typical home value in **dollars (USD)** for that month. ZHVI aims to represent the “middle” of the housing stock (e.g., 35th–65th percentile). Values in the hundreds of thousands are normal for many California ZIPs; very low values (e.g., under 50,000) or extremely high ones may indicate data issues or unusual markets. Geography is given by RegionID, RegionName (ZIP code), State, Metro, and CountyName.\n",
    "\n",
    "**Concerns.** (1) This mirror ends in 2018; for newer years we would use official Zillow Research data. (2) Coverage can be better in active listing markets, so some rural or low-transaction ZIPs may be missing or noisier. (3) Single-family only, so condos and multi-family are excluded. (4) We filter to California and UC-adjacent counties, so national coverage is not used in the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (15508, 280)\n",
      "Columns (first 10 and last 5): ['RegionID', 'RegionName', 'City', 'State', 'Metro', 'CountyName', 'SizeRank', '1996-04', '1996-05', '1996-06', '...', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12']\n",
      "\n",
      "Rows (CA only): 1229\n",
      "\n",
      "Missing in key cols:\n",
      "RegionID       0\n",
      "RegionName     0\n",
      "State          0\n",
      "CountyName     0\n",
      "Metro         45\n",
      "dtype: int64\n",
      "Sample missing % (first date col): 0.0\n",
      "Sample missing % (last date col): 0.0\n",
      "\n",
      "Rows after dropping all-NaN/all-zero date rows: 1229\n",
      "\n",
      "Saved cleaned CA ZHVI to data/02-processed/zhvi_sfr_zip_ca_2018.csv\n",
      "\n",
      "Summary of 2018-12 (CA ZIPs):\n",
      "count    1.229000e+03\n",
      "mean     7.485329e+05\n",
      "std      6.628661e+05\n",
      "min      1.171000e+05\n",
      "25%      3.533000e+05\n",
      "50%      5.685000e+05\n",
      "75%      8.854000e+05\n",
      "max      6.671700e+06\n",
      "Name: 2018-12, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path_raw = 'data/00-raw/Zip_Zhvi_SingleFamilyResidence_2018.csv'\n",
    "zhvi_raw = pd.read_csv(path_raw)\n",
    "\n",
    "print('Shape:', zhvi_raw.shape)\n",
    "print('Columns (first 10 and last 5):', list(zhvi_raw.columns[:10]) + ['...'] + list(zhvi_raw.columns[-5:]))\n",
    "\n",
    "zhvi_ca = zhvi_raw[zhvi_raw['State'] == 'CA'].copy()\n",
    "print('\\nRows (CA only):', len(zhvi_ca))\n",
    "\n",
    "key_cols = ['RegionID', 'RegionName', 'State', 'CountyName', 'Metro']\n",
    "date_cols = [c for c in zhvi_ca.columns if c not in key_cols]\n",
    "print('\\nMissing in key cols:')\n",
    "print(zhvi_ca[key_cols].isna().sum())\n",
    "print('Sample missing % (first date col):', zhvi_ca[date_cols[0]].isna().mean().round(4))\n",
    "print('Sample missing % (last date col):', zhvi_ca[date_cols[-1]].isna().mean().round(4))\n",
    "\n",
    "date_vals = zhvi_ca[date_cols]\n",
    "zhvi_ca = zhvi_ca[(date_vals.notna().any(axis=1)) & (date_vals != 0).any(axis=1)]\n",
    "print('\\nRows after dropping all-NaN/all-zero date rows:', len(zhvi_ca))\n",
    "\n",
    "os.makedirs('data/02-processed', exist_ok=True)\n",
    "zhvi_ca.to_csv('data/02-processed/zhvi_sfr_zip_ca_2018.csv', index=False)\n",
    "print('\\nSaved cleaned CA ZHVI to data/02-processed/zhvi_sfr_zip_ca_2018.csv')\n",
    "\n",
    "last_col = date_cols[-1]\n",
    "print('\\nSummary of', last_col, '(CA ZIPs):')\n",
    "print(zhvi_ca[last_col].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### American Community Survey (ACS) — Median Household Income\n",
    "\n",
    "**Metrics and units.** This dataset comes from the American Community Survey (ACS) 5-Year Estimates, Table B19013, published by the U.S. Census Bureau. It contains county-level estimates of **median household income measured in U.S. dollars (USD)**. Each row represents one county observation per year. The key variable is median household income, which represents the midpoint of the household income distribution within a county. This means half of households earn more than the median income and half earn less.\n",
    "\n",
    "Median household income is an important economic indicator because it reflects the general income level and economic well-being of residents in a geographic region. Higher median income values typically indicate greater economic resources available to households, while lower values may reflect economic disadvantage or limited employment opportunities. Because the ACS provides standardized estimates across counties, this dataset allows comparison of income levels across regions and over time.\n",
    "\n",
    "**Concerns.** (1) ACS values are estimates derived from survey sampling rather than complete administrative records, so there may be sampling error or uncertainty in the reported values. (2) Median household income does not capture income inequality within a county. (3) The dataset does not account for differences in cost of living across regions, which may affect comparability.\n",
    "\n",
    "**Combining with Zillow.** Zillow ZHVI data are aggregated at the ZIP level, while ACS income data are at the county level. We will merge datasets using county name (or FIPS if available) so each county has both a housing value measure and a corresponding income measure. This allows comparison of housing price levels with median income across California counties and UC regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (58, 42)\n",
      "Columns: ['County', 'AMI', 'ALI_1', 'ALI_2', 'ALI_3', 'ALI_4', 'ALI_5', 'ALI_6', 'ALI_7', 'ALI_8', 'ELI_1', 'ELI_2', 'ELI_3', 'ELI_4', 'ELI_5', 'ELI_6', 'ELI_7', 'ELI_8', 'VLI_1', 'VLI_2', 'VLI_3', 'VLI_4', 'VLI_5', 'VLI_6', 'VLI_7', 'VLI_8', 'LI_1', 'LI_2', 'LI_3', 'LI_4', 'LI_5', 'LI_6', 'LI_7', 'LI_8', 'MOD_1', 'MOD_2', 'MOD_3', 'MOD_4', 'MOD_5', 'MOD_6', 'MOD_7', 'MOD_8']\n",
      "\n",
      "Missing counts:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "County column used: County | Unique counties: 58\n",
      "Saved to data/02-processed/ca_income_limits_2022.csv\n",
      "\n",
      "Sample counties (income): ['Alameda' 'Alpine' 'Amador' 'Butte' 'Calaveras' 'Colusa' 'Contra Costa'\n",
      " 'Del Norte' 'El Dorado' 'Fresno']\n",
      "Sample counties (Zillow CA): ['San Francisco County' 'Los Angeles County' 'Contra Costa County'\n",
      " 'Alameda County' 'Sacramento County' 'Orange County' 'Napa County'\n",
      " 'San Diego County' 'Fresno County' 'Solano County']\n"
     ]
    }
   ],
   "source": [
    "path_income = 'data/00-raw/2022-income-limits.csv'\n",
    "income_raw = pd.read_csv(path_income)\n",
    "\n",
    "print('Shape:', income_raw.shape)\n",
    "print('Columns:', list(income_raw.columns))\n",
    "\n",
    "print('\\nMissing counts:')\n",
    "print(income_raw.isna().sum()[income_raw.isna().sum() > 0])\n",
    "\n",
    "if 'State' in income_raw.columns:\n",
    "    income_ca = income_raw[income_raw['State'] == 'CA'].copy()\n",
    "else:\n",
    "    income_ca = income_raw.copy()\n",
    "\n",
    "county_col = None\n",
    "for c in income_ca.columns:\n",
    "    if c == 'County' or 'county' in c.lower():\n",
    "        county_col = c\n",
    "        break\n",
    "if county_col is None:\n",
    "    county_col = income_ca.columns[0]\n",
    "print('\\nCounty column used:', county_col, '| Unique counties:', income_ca[county_col].nunique())\n",
    "\n",
    "income_ca.to_csv('data/02-processed/ca_income_limits_2022.csv', index=False)\n",
    "print('Saved to data/02-processed/ca_income_limits_2022.csv')\n",
    "\n",
    "print('\\nSample counties (income):', income_ca[county_col].dropna().unique()[:10])\n",
    "print('Sample counties (Zillow CA):', zhvi_ca['CountyName'].dropna().unique()[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### American Community Survey (ACS) — Median Household Income\n",
    "\n",
    "**Metrics and units.**  \n",
    "This dataset comes from the American Community Survey (ACS) 5-Year Estimates, Table B19013, published by the U.S. Census Bureau. It contains county-level estimates of median household income measured in **U.S. dollars (USD)**. Each row represents a county observation, and the key variable is median household income, which represents the midpoint of household income distribution within a county. This means half of households earn more than the median income and half earn less.\n",
    "\n",
    "**Relevance.**  \n",
    "Median household income is an important economic indicator because it reflects the general income level and economic well-being of residents in a geographic region. Higher median income values typically indicate greater economic resources available to households, while lower values may reflect economic disadvantage or limited employment opportunities. Because the ACS provides standardized estimates across counties, this dataset allows comparison of income levels across regions and over time.\n",
    "\n",
    "**Concerns.**  \n",
    "ACS values are estimates derived from survey sampling rather than complete administrative records. As a result, there may be sampling error or uncertainty in the reported values. Additionally, median household income does not capture income inequality within a county and does not account for differences in cost of living across regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/00-raw/COGS 108 data/productDownload_2026-02-18T022323/ACSDT5Y2023.B19013-Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/00-raw/COGS 108 data/productDownload_2026-02-18T022323/ACSDT5Y2023.B19013-Data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal columns:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/00-raw/COGS 108 data/productDownload_2026-02-18T022323/ACSDT5Y2023.B19013-Data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "data_path = \"data/00-raw/COGS 108 data/productDownload_2026-02-18T022323/ACSDT5Y2023.B19013-Data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Original columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nOriginal shape:\", df.shape)\n",
    "\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"NAME\": \"county\",\n",
    "    \"B19013_001E\": \"median_household_income\"\n",
    "})\n",
    "\n",
    "df = df[[\"county\", \"median_household_income\"]]\n",
    "\n",
    "df[\"median_household_income\"] = pd.to_numeric(\n",
    "    df[\"median_household_income\"],\n",
    "    errors=\"coerce\"\n",
    ")\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"\\nCleaned dataset shape:\", df.shape)\n",
    "\n",
    "print(\"\\nPreview of cleaned dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df[\"median_household_income\"].describe())\n",
    "\n",
    "\n",
    "os.makedirs(\"data/02-processed\", exist_ok=True)\n",
    "\n",
    "df.to_csv(\"data/02-processed/acs_income_2023.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved to data/02-processed/acs_income_2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only aggregated, publicly available data (Zillow, Census/ACS, CA Open Data). There are no human subjects. We considered collection bias (Zillow may overrepresent urban/higher-income markets; we state this and examine regional differences), PII (none collected), and dataset bias (we avoid normative claims and frame results as regional trends). Data are stored in the repo with normal access; no model is deployed. See the full Ethics checklist in 00-ProjectProposal.ipynb for all items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All team members have read the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) and agree to the following expectations.\n",
    "\n",
    "* **Communication.** Communicate regularly through a shared platform (e.g., Discord or Slack) and attend scheduled meetings.\n",
    "* **Contribution.** Each member is expected to contribute equitably to data collection, analysis, and writing.\n",
    "* **Conflict resolution.** If conflicts arise, we agree to address them respectfully and promptly through group discussion.\n",
    "* **Commitment.** By submitting this proposal, each member affirms that they have read the COGS 108 Team Policies and intend to meet these expectations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not anticipate needing specialized methods beyond those covered in COGS 108. Standard data analysis, visualization, and basic statistical techniques should be sufficient.\n",
    "\n",
    "| Week | Completed Before | Discuss / Deliverables |\n",
    "|------|------------------|-------------------------|\n",
    "| 3 to 4 | Finalize research question and identify datasets (Zillow, Census/ACS, FRED) | Confirm data access and align on UC regions (e.g., Irvine, La Jolla, Berkeley, LA) |\n",
    "| 5 | Data cleaning and preprocessing | Joined region-time tables, consistent geography and time range |\n",
    "| 6 | Exploratory data analysis and visualization | Price and income trends, price difference and income comparison visuals |\n",
    "| 7 | Statistical analysis and interpretation | Compare price vs. income growth, affordability by region |\n",
    "| 8 | Draft results and ethics discussion | Integrate limitations and ethics, first full draft |\n",
    "| 9 | Finalize analysis and visualizations | Polished figures and tables, finalize methods and results |\n",
    "| 10 | Complete final report and presentation | Turn in final project and group surveys |\n",
    "\n",
    "**Update for Data Checkpoint:** We obtained Zillow ZHVI (ZIP, single-family) and CA county income limits. Next we will add Census ACS median household income by county/year for time trends and refine the county list for UC-adjacent regions before EDA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
